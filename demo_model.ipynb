{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/amold/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run following code only once to download brown dataset to local system\n",
    "# import nltk\n",
    "# nltk.download('brown')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS EXAMPLE: ['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', \"atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.', 'the', 'jury', 'further', 'said', 'in']\n",
      "\n",
      "\n",
      "VOCAB EXAMPLE: ['spice-laden', 'titer', 'preach', 'potowomut', 'tartary', 'incompleteness', 'flute', 'bit-like', 'carloading', 'notre']\n"
     ]
    }
   ],
   "source": [
    "# Loading the corpus\n",
    "corpus = brown.words()\n",
    "\n",
    "# Case folding and getting vocab\n",
    "lower_case_corpus = [w.lower() for w in corpus]\n",
    "vocab = set(lower_case_corpus)\n",
    "\n",
    "print('CORPUS EXAMPLE: ' + str(lower_case_corpus[:30]) + '\\n\\n')\n",
    "print('VOCAB EXAMPLE: ' + str(list(vocab)[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in Corpus: 1161192\n",
      "Vocab of the Corpus: 49815\n"
     ]
    }
   ],
   "source": [
    "print('Total words in Corpus: ' + str(len(lower_case_corpus)))\n",
    "print('Vocab of the Corpus: ' + str(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example, count for bigram ('the', 'king') is: 51\n"
     ]
    }
   ],
   "source": [
    "bigram_counts = {}\n",
    "trigram_counts = {}\n",
    "\n",
    "# Sliding through corpus to get bigram and trigram counts\n",
    "for i in range(len(lower_case_corpus) - 2):\n",
    "    # Getting bigram and trigram at each slide\n",
    "    bigram = (lower_case_corpus[i], lower_case_corpus[i+1])\n",
    "    trigram = (lower_case_corpus[i], lower_case_corpus[i+1], lower_case_corpus[i+2])\n",
    "    \n",
    "    # Keeping track of the bigram counts\n",
    "    if bigram in bigram_counts.keys():\n",
    "        bigram_counts[bigram] += 1\n",
    "    else:\n",
    "        bigram_counts[bigram] = 1\n",
    "    \n",
    "    # Keeping track of trigram counts\n",
    "    if trigram in trigram_counts.keys():\n",
    "        trigram_counts[trigram] += 1\n",
    "    else:\n",
    "        trigram_counts[trigram] = 1\n",
    "\n",
    "print(\"Example, count for bigram ('the', 'king') is: \" + str(bigram_counts[('the', 'king')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function takes sentence as input and suggests possible words that comes after the sentence  \n",
    "def suggest_next_word(input_, bigram_counts, trigram_counts, vocab):\n",
    "    # Consider the last bigram of sentence\n",
    "    tokenized_input = word_tokenize(input_.lower())\n",
    "    last_bigram = tokenized_input[-2:]\n",
    "    \n",
    "    # Calculating probability for each word in vocab\n",
    "    vocab_probabilities = {}\n",
    "    for vocab_word in vocab:\n",
    "        test_trigram = (last_bigram[0], last_bigram[1], vocab_word)\n",
    "        test_bigram = (last_bigram[0], last_bigram[1])\n",
    "\n",
    "        test_trigram_count = trigram_counts.get(test_trigram, 0)\n",
    "        test_bigram_count = bigram_counts.get(test_bigram, 0)\n",
    "        \n",
    "        probability = test_trigram_count / test_bigram_count\n",
    "        vocab_probabilities[vocab_word] = probability\n",
    "    \n",
    "    # Sorting the vocab probability in descending order to get top probable words\n",
    "    top_suggestions = sorted(vocab_probabilities.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    return top_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('james', 0.17647058823529413),\n",
       " ('of', 0.1568627450980392),\n",
       " ('arthur', 0.11764705882352941)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_next_word('I am the king', bigram_counts, trigram_counts, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes as input a starting sentence and then keeps picking top probability words until certain condition is met\n",
    "def generate_sequence(input_, bigram_counts, trigram_counts, vocab):\n",
    "    sentence = input_.lower()\n",
    "    next_word_prob = 1.0\n",
    "    while(1):\n",
    "        # fetch the most probably word based on n-gram model\n",
    "        next_word_suggestions = suggest_next_word(sentence, bigram_counts, trigram_counts, vocab)\n",
    "        next_word, next_word_prob = next_word_suggestions[0]\n",
    "        # append top probability word to sentence\n",
    "        sentence = sentence + ' ' + next_word\n",
    "        # condition to break while loop and end word generation\n",
    "        if next_word_prob < 0.01 or next_word == '.' or len(sentence) > 100:\n",
    "            break\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am the king james version has little effect on the other hand , the first time in the world .'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequence('I am the king', bigram_counts, trigram_counts, vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
